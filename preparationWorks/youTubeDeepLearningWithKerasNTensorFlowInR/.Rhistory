setwd("~/")
install.packages("swirl")
library(swirl)
swirl()
5+7
x <- 5 + 7
x
y <- x - 3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555)
c(z, 555, z)
z * 2 + 100
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 1000
my_div
avg(c(2.23, 3.45, 1.87, 2.11, 7.33, 18.34, 19.23))
mean(c(2.23, 3.45, 1.87, 2.11, 7.33, 18.34, 19.23))
swirl()
bye()
for (var in 1:25) {}
num <- 0
for (var in 1:25) {
num <- num + var^2
}
num
class(cars)
nrow(cars)
head(cars, 1)
cars[,2]
mean(cars[,2])
which(cars$dist == 85)
swirl()
main()
getwd()
ls()
x <- 9
ls()
ls()
list.files()
?list.files
args(list.files)
old.dir <- "C:/Users/Eric/Documents"
old.dir <- getwd()
dir.create("testdir")
setwd(testdir)
setwd("testdir")
getwd
getwd()
file.create("mytest.R")
list.files()
file.exists("mytest.R")
file.info("mytest.R")
file.rename("mytest.R", "mytest2.R")
file.copy("mytest2.R", "mytest3.R")
play()
1+1
nxt()
file.path("mytest3.R")
file.path("folder1")
file.path("folder1", "folder2")
?dir.create
dir.create("testdir2/testdir3", recursive = TRUE)
dir.create(file.path("testdir2", 'testdir3', recursive = TRUE)
)
dir.create(file.path("testdir2", 'testdir3', recursive = TRUE))
dir.create(file.path('testdir2', 'testdir3', recursive = TRUE))
play()
getwd
getwd()
nxt()
dir.create(file.path('testdir2', 'testdir3', recursive = TRUE))
dir.create(file.path('testdir2', 'testdir3'), recursive = TRUE)
setwd(old.dir)
rm(list = ls())
setwd
setwd(dirname(file.choose()))
# Import keras package
library(keras)
install_keras()
conda_create("r-reticulate")
use_condaenv("r_reticulate")
data <- read.csv(file.choose(), header = T)
data <- as.matrix(data)
dimnames(data) <- NULL
data[, 1:21] <- normalize(data[, 1:21])
data[,22] <- as.numeric(data[,22]) -1
# Data partition
set.seed(1234)
ind <- sample(2, nrow(data), replace = T, prob = c(0.7, 0.3))
training <- data[ind==1, 1:21]
test <- data[ind==2, 1:21]
trainingtarget <- data[ind==1, 22]
testtarget <- data[ind==2, 22]
# One Hot Encoding
trainLabels <- to_categorical(trainingtarget)
testLabels <- to_categorical(testtarget)
# Create sequential model
model <- keras_model_sequential()
model %>%
layer_dense(units=8, activation = relu, input_shape = c(21) %>%
layer_dense(units = 3, activation = 'softmax')
summary(model)
model %>%
layer_dense(units=8, activation = relu, input_shape = c(21) %>%
layer_dense(units = 3, activation = 'softmax')
)
model %>%
layer_dense(units=8, activation = relu, input_shape = c(21)) %>%
layer_dense(units = 3, activation = 'softmax')
model %>%
layer_dense(units=8, activation = 'relu', input_shape = c(21)) %>%
layer_dense(units = 3, activation = 'softmax')
summary(model)
# Compile
model %>%
compile(loss = 'categorical_crossentropy,
optimizer = 'adam',
metrics = 'accuracy')
# Compile
model %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
# Fit model
history <- model %>%
fit(training,
trainLabels,
epoch = 200,
batch_size = 32,
validation_split = 0.2)
plot(history)
# Evaluate model with test data
model1 <- model %>%
evaluate(test, testLabels)
# Prediction & confusion matrix - test data
prob <- model %>%
predict_proba(test)
pred <- model %>%
predict_classes(test)
table <- table(Predicted = pred, Actual = testtarget)
table
cbind(prob, pred, testtarget)
model <- keras_model_sequential()
model %>%
layer_dense(units=50, activation = 'relu', input_shape = c(21)) %>%
layer_dense(units = 3, activation = 'softmax')
# Compile
model %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
# Fit model
history <- model %>%
fit(training,
trainLabels,
epoch = 200,
batch_size = 32,
validation_split = 0.2)
plot(history)
# Evaluate model with test data
model <- model %>%
evaluate(test, testLabels)
# Prediction & confusion matrix - test data
prob <- model %>%
predict_proba(test)
pred <- model %>%
predict_classes(test)
table <- table(Predicted = pred, Actual = testtarget)
table
## 2nd: units = 50
model <- keras_model_sequential()
model %>%
layer_dense(units=50, activation = 'relu', input_shape = c(21)) %>%
layer_dense(units = 3, activation = 'softmax')
# Compile
model %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
# Fit model
history <- model %>%
fit(training,
trainLabels,
epoch = 200,
batch_size = 32,
validation_split = 0.2)
plot(history)
# Evaluate model with test data
model1 <- model %>%
evaluate(test, testLabels)
# Prediction & confusion matrix - test data
prob <- model %>%
predict_proba(test)
pred <- model %>%
predict_classes(test)
table <- table(Predicted = pred, Actual = testtarget)
table
model <- keras_model_sequential()
model %>%
layer_dense(units=50, activation = 'relu', input_shape = c(21)) %>%
layer_dense(units=8, activation = 'relu') %>%
layer_dense(units = 3, activation = 'softmax')
# Compile
model %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
# Fit model
history <- model %>%
fit(training,
trainLabels,
epoch = 200,
batch_size = 32,
validation_split = 0.2)
plot(history)
# Evaluate model with test data
model1 <- model %>%
evaluate(test, testLabels)
# Prediction & confusion matrix - test data
prob <- model %>%
predict_proba(test)
pred <- model %>%
predict_classes(test)
table <- table(Predicted = pred, Actual = testtarget)
table
## try different number of layers and units
model <- keras_model_sequential()
model %>%
layer_dense(units=84, activation = 'relu', input_shape = c(21)) %>%
layer_dense(units=42, activation = 'relu') %>%
layer_dense(units=21, activation = 'relu') %>%
layer_dense(units = 3, activation = 'softmax')
# Compile
model %>%
compile(loss = 'categorical_crossentropy',
optimizer = 'adam',
metrics = 'accuracy')
# Fit model
history <- model %>%
fit(training,
trainLabels,
epoch = 200,
batch_size = 32,
validation_split = 0.2)
# Evaluate model with test data
model1 <- model %>%
evaluate(test, testLabels)
# Prediction & confusion matrix - test data
prob <- model %>%
predict_proba(test)
pred <- model %>%
predict_classes(test)
table <- table(Predicted = pred, Actual = testtarget)
table
exit
quit()
